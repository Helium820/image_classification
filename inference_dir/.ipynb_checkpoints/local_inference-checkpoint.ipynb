{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model inference interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### blank cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T07:14:11.491377Z",
     "start_time": "2019-02-16T07:14:11.475446Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "model_name = \"faster_rcnn_resnet152_v1_640x640_coco17_tpu-8_cloud_detection_dataset_5-class_2021_09_15_2021_09_15_reshuffled\"\n",
    "\n",
    "base_path=\"YOUR_COMPUTER_BASE_PATH\"\n",
    "exported_model_path=f\"{base_path}/exported-models\"\n",
    "label_map_dir=f\"{base_path}/annotations\"\n",
    "\n",
    "PATH_TO_SAVED_MODEL = Path(exported_model_path) / Path(model_name + '_ckpt-31') / Path('saved_model')\n",
    "PATH_TO_LABEL_MAP = Path(label_map_dir) / Path(model_name) / Path('label_map.pbtxt')\n",
    "PATH_TO_TEST_IMAGES_DIR = Path(base_path) / Path('input')\n",
    "PATH_TO_OUTPUT_IMAGES_DIR = Path(base_path) / Path('output')\n",
    "\n",
    "assert os.path.isdir(PATH_TO_SAVED_MODEL)\n",
    "assert os.path.isfile(PATH_TO_LABEL_MAP)\n",
    "assert os.path.isdir(PATH_TO_TEST_IMAGES_DIR)\n",
    "assert os.path.isdir(PATH_TO_OUTPUT_IMAGES_DIR)\n",
    "\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg\"))\n",
    "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
    "\n",
    "num_images = len(TEST_IMAGE_PATHS)\n",
    "print(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print('BEGIN loading model')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(str(PATH_TO_SAVED_MODEL))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('DONE loading model. Took {:.2f} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T07:14:27.590771Z",
     "start_time": "2019-02-16T07:14:11.953134Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(str(PATH_TO_LABEL_MAP))\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=len(label_map.item), use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(image_path, detect_fn):\n",
    "    print('BEGIN running inference for {}'.format(image_path))\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {\n",
    "        key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'],\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        #instance_masks=detections.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=100,\n",
    "        #line_thickness=8,\n",
    "        min_score_thresh=0.50,\n",
    "        agnostic_mode=False)\n",
    "\n",
    "    # below is for debug\n",
    "    im_height, im_width, im_num_ch = image_np.shape\n",
    "    #for idx, box in enumerate(detections['detection_boxes']):\n",
    "    #    if detections['detection_scores'][idx] >= 0.5:\n",
    "    #        [ymin, xmin, ymax, xmax] = box\n",
    "    #        (left, right, top, bottom) = (\n",
    "    #            int(xmin * im_width), int(xmax * im_width),\n",
    "    #            int(ymin * im_height), int(ymax * im_height))\n",
    "    #        print(\"(left, right, top, bottom) = ({}, {}, {}, {})\".format(left, right, top, bottom))\n",
    "    #plt.figure()\n",
    "    #plt.imshow(image_np_with_detections)\n",
    "    im = Image.fromarray(image_np_with_detections)\n",
    "    im.save(Path(PATH_TO_OUTPUT_IMAGES_DIR) / Path(os.path.basename(image_path)))\n",
    "    print('DONE running inference for {}'.format(image_path))\n",
    "\n",
    "    return detections\n",
    "\n",
    "start_time = time.time()\n",
    "print('BEGIN running inference for testing dataset')\n",
    "for image_idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "    print('PROGRESS: {}/{}'.format(image_idx+1, num_images))\n",
    "    output_dict = run_inference_for_single_image(image_path, detect_fn)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "elapsed_time_per_image = elapsed_time/num_images\n",
    "print('DONE running inference for testing dataset. Took {:.2f} seconds per image'.format(elapsed_time_per_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
